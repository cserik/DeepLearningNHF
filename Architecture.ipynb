{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Architecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cserik/DeepLearningNHF/blob/main/Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ide_tv0HPHM0"
      },
      "source": [
        "#import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, AveragePooling2D, Flatten, BatchNormalization, Add, LeakyReLU,UpSampling2D, Reshape\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras import backend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZkiMx8eMhIC"
      },
      "source": [
        "# load the prepared dataset\n",
        "from numpy import load\n",
        "# load the face dataset\n",
        "data = load('img_celeba_256.npz')\n",
        "all_faces = data['arr_0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47wJ9Trw_elt"
      },
      "source": [
        "def normalize(x):\n",
        "\t# extract numpy array\n",
        "\tX = x\n",
        "\t# convert from ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [0,1]\n",
        "\tX = X / 255.0\n",
        "\treturn X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhCsHFsxGlYH"
      },
      "source": [
        "# generate mini batch\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images and normalization\n",
        "\tX = normalize(dataset[ix])\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = np.ones((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQlfZZGGw6sB"
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8cJSyESwsHt"
      },
      "source": [
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUIGCNQ3MQlL"
      },
      "source": [
        "# fake samples mini batch (noise)\n",
        "def get_fake_samples(n_samples):\n",
        "\n",
        "\t# retrieve selected images and normalization\n",
        "\tnoise=np.random.rand(n_samples,256,256,3)\n",
        "\t# generate 'fake' class labels (0)\n",
        "\ty = np.ones((n_samples, 0))\n",
        "\treturn noise, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UEuAUCU01S8"
      },
      "source": [
        "init = RandomNormal(stddev=0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3jCpPQQm2Tv"
      },
      "source": [
        "# weighted sum output\n",
        "class WeightedSum(Add):\n",
        "\t# init with default value\n",
        "\tdef __init__(self, alpha=0.0, **kwargs):\n",
        "\t\tsuper(WeightedSum, self).__init__(**kwargs)\n",
        "\t\tself.alpha = backend.variable(alpha, name='ws_alpha')\n",
        " \n",
        "\t# output a weighted sum of inputs\n",
        "\tdef _merge_function(self, inputs):\n",
        "\t\t# only supports a weighted sum of two inputs\n",
        "\t\tassert (len(inputs) == 2)\n",
        "\t\t# ((1-a) * input1) + (a * input2)\n",
        "\t\toutput = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
        "\t\treturn output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7GvOnDPq_Fy"
      },
      "source": [
        "# add a discriminator block\n",
        "def add_discriminator_block(old_model, n_input_layers=3):\n",
        "\t# get shape of existing model\n",
        "\tin_shape = list(old_model.input.shape)\n",
        "\t# define new input shape as double the size\n",
        "\tinput_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n",
        "\tin_image = Input(shape=input_shape)\n",
        "\t# define new input processing layer\n",
        "\td = Conv2D(64, (1,1), padding='same', kernel_initializer='he_normal')(in_image)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# define new block\n",
        "\td = Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = AveragePooling2D()(d)\n",
        "\tblock_new = d\n",
        "\t# skip the input, 1x1 and activation for the old model\n",
        "\tfor i in range(n_input_layers, len(old_model.layers)):\n",
        "\t\td = old_model.layers[i](d)\n",
        "\t# define straight-through model\n",
        "\tmodel1 = Model(in_image, d)\n",
        "\t# compile model\n",
        "\tmodel1.compile(loss='mse', optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\t# downsample the new larger image\n",
        "\tdownsample = AveragePooling2D()(in_image)\n",
        "\t# connect old input processing to downsampled new input\n",
        "\tblock_old = old_model.layers[1](downsample)\n",
        "\tblock_old = old_model.layers[2](block_old)\n",
        "\t# fade in output of old model input layer with new input\n",
        "\td = WeightedSum()([block_old, block_new])\n",
        "\t# skip the input, 1x1 and activation for the old model\n",
        "\tfor i in range(n_input_layers, len(old_model.layers)):\n",
        "\t\td = old_model.layers[i](d)\n",
        "\t# define straight-through model\n",
        "\tmodel2 = Model(in_image, d)\n",
        "\t# compile model\n",
        "\tmodel2.compile(loss='mse', optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\treturn [model1, model2]\n",
        " \n",
        "# define the discriminator models for each image resolution\n",
        "def define_discriminator(n_blocks, input_shape=(4,4,3)):\n",
        "\tmodel_list = list()\n",
        "\t# base model input\n",
        "\tin_image = Input(shape=input_shape)\n",
        "\t# conv 1x1\n",
        "\td = Conv2D(64, (1,1), padding='same', kernel_initializer='he_normal')(in_image)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# conv 3x3 (output block)\n",
        "\td = Conv2D(128, (3,3), padding='same', kernel_initializer='he_normal')(d)\n",
        "\td=BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# conv 4x4\n",
        "\td = Conv2D(128, (4,4), padding='same', kernel_initializer='he_normal')(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# dense output layer\n",
        "\td = Flatten()(d)\n",
        "\tout_class = Dense(1)(d)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, out_class)\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='mse', optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\t# store model\n",
        "\tmodel_list.append([model, model])\n",
        "\t# create submodels\n",
        "\tfor i in range(1, n_blocks):\n",
        "\t\t# get prior model without the fade-on\n",
        "\t\told_model = model_list[i - 1][0]\n",
        "\t\t# create new model for next resolution\n",
        "\t\tmodels = add_discriminator_block(old_model)\n",
        "\t\t# store model\n",
        "\t\tmodel_list.append(models)\n",
        "\treturn model_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it60XF5inCf5"
      },
      "source": [
        "#generator \n",
        "# add a generator block\n",
        "def add_generator_block(old_model):\n",
        "\t# get the end of the last block\n",
        "\tblock_end = old_model.layers[-2].output\n",
        "\t# upsample, and define new block\n",
        "\tupsampling = UpSampling2D()(block_end)\n",
        "\tg = Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(upsampling)\n",
        "\tg = BatchNormalization()(g)\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\tg = Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(g)\n",
        "\tg = BatchNormalization()(g)\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\t# add new output layer\n",
        "\tout_image = Conv2D(3, (1,1), padding='same', kernel_initializer='he_normal')(g)\n",
        "\t# define model\n",
        "\tmodel1 = Model(old_model.input, out_image)\n",
        "\t# get the output layer from old model\n",
        "\tout_old = old_model.layers[-1]\n",
        "\t# connect the upsampling to the old output layer\n",
        "\tout_image2 = out_old(upsampling)\n",
        "\t# define new output image as the weighted sum of the old and new models\n",
        "\tmerged = WeightedSum()([out_image2, out_image])\n",
        "\t# define model\n",
        "\tmodel2 = Model(old_model.input, merged)\n",
        "\treturn [model1, model2]\n",
        " \n",
        "# define generator models\n",
        "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
        "\tmodel_list = list()\n",
        "\t# base model latent input\n",
        "\tin_latent = Input(shape=(latent_dim,))\n",
        "\t# linear scale up to activation maps\n",
        "\tg  = Dense(128 * in_dim * in_dim, kernel_initializer='he_normal')(in_latent)\n",
        "\tg = Reshape((in_dim, in_dim, 128))(g)\n",
        "\t# conv 4x4, input block\n",
        "\tg = Conv2D(128, (3,3), padding='same', kernel_initializer='he_normal')(g)\n",
        "\tg = BatchNormalization()(g)\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\t# conv 3x3\n",
        "\tg = Conv2D(128, (3,3), padding='same', kernel_initializer='he_normal')(g)\n",
        "\tg = BatchNormalization()(g)\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\t# conv 1x1, output block\n",
        "\tout_image = Conv2D(3, (1,1), padding='same', kernel_initializer='he_normal')(g)\n",
        "\t# define model\n",
        "\tmodel = Model(in_latent, out_image)\n",
        "\t# store model\n",
        "\tmodel_list.append([model, model])\n",
        "\t# create submodels\n",
        "\tfor i in range(1, n_blocks):\n",
        "\t\t# get prior model without the fade-on\n",
        "\t\told_model = model_list[i - 1][0]\n",
        "\t\t# create new model for next resolution\n",
        "\t\tmodels = add_generator_block(old_model)\n",
        "\t\t# store model\n",
        "\t\tmodel_list.append(models)\n",
        "\treturn model_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idGGn-jxnw-s"
      },
      "source": [
        "# define composite models for training generators via discriminators\n",
        "def define_composite(discriminators, generators):\n",
        "\tmodel_list = list()\n",
        "\t# create composite models\n",
        "\tfor i in range(len(discriminators)):\n",
        "\t\tg_models, d_models = generators[i], discriminators[i]\n",
        "\t\t# straight-through model\n",
        "\t\td_models[0].trainable = False\n",
        "\t\tmodel1 = Sequential()\n",
        "\t\tmodel1.add(g_models[0])\n",
        "\t\tmodel1.add(d_models[0])\n",
        "\t\tmodel1.compile(loss='mse', optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\t\t# fade-in model\n",
        "\t\td_models[1].trainable = False\n",
        "\t\tmodel2 = Sequential()\n",
        "\t\tmodel2.add(g_models[1])\n",
        "\t\tmodel2.add(d_models[1])\n",
        "\t\tmodel2.compile(loss='mse', optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\t\t# store\n",
        "\t\tmodel_list.append([model1, model2])\n",
        "\treturn model_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHZEv8D_oe-h"
      },
      "source": [
        "# scale images to preferred size\n",
        "def scale_dataset(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tUt9FdGv9J_"
      },
      "source": [
        "# train a generator and discriminator\n",
        "def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False):\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# calculate the size of half a batch of samples\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# update alpha for all WeightedSum layers when fading in new blocks\n",
        "\t\tif fadein:\n",
        "\t\t\tupdate_fadein([g_model, d_model, gan_model], i, n_steps)\n",
        "\t\t# prepare real and fake samples\n",
        "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t# update discriminator model\n",
        "\t\td_loss1 = d_model.train_on_batch(X_real, y_real)\n",
        "\t\td_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t# update the generator via the discriminator's error\n",
        "\t\tz_input = generate_latent_points(latent_dim, n_batch)\n",
        "\t\ty_real2 = ones((n_batch, 1))\n",
        "\t\tg_loss = gan_model.train_on_batch(z_input, y_real2)\n",
        "\t\t# summarize loss on this batch\n",
        "\t\tprint('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seeBTUC0pGhg"
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch):\n",
        "\t# fit the baseline model\n",
        "\tg_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
        "\t# scale dataset to appropriate size\n",
        "\tgen_shape = g_normal.output_shape\n",
        "\tscaled_data = scale_dataset(dataset, gen_shape[1:])\n",
        "\tprint('Scaled Data', scaled_data.shape)\n",
        "\t# train normal or straight-through models\n",
        "\ttrain_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm, n_batch)\n",
        "\t# process each level of growth\n",
        "\tfor i in range(1, len(g_models)):\n",
        "\t\t# retrieve models for this level of growth\n",
        "\t\t[g_normal, g_fadein] = g_models[i]\n",
        "\t\t[d_normal, d_fadein] = d_models[i]\n",
        "\t\t[gan_normal, gan_fadein] = gan_models[i]\n",
        "\t\t# scale dataset to appropriate size\n",
        "\t\tgen_shape = g_normal.output_shape\n",
        "\t\tscaled_data = scale_dataset(dataset, gen_shape[1:])\n",
        "\t\tprint('Scaled Data', scaled_data.shape)\n",
        "\t\t# train fade-in models for next level of growth\n",
        "\t\ttrain_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein, n_batch, True)\n",
        "\t\t# train normal or straight-through models\n",
        "\t\ttrain_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm, n_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIIssx6DxyUL"
      },
      "source": [
        "# update the alpha value on each instance of WeightedSum\n",
        "def update_fadein(models, step, n_steps):\n",
        "\t# calculate current alpha (linear from 0 to 1)\n",
        "\talpha = step / float(n_steps - 1)\n",
        "\t# update the alpha for each model\n",
        "\tfor model in models:\n",
        "\t\tfor layer in model.layers:\n",
        "\t\t\tif isinstance(layer, WeightedSum):\n",
        "\t\t\t\tbackend.set_value(layer.alpha, alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pzziuV8Qpa0t",
        "outputId": "14b55444-bd2a-4bbf-92da-1a7cf74e1b36"
      },
      "source": [
        "from skimage.transform import resize\n",
        "from numpy import asarray\n",
        "from numpy.random import randn\n",
        "# example of progressive growing gan on celebrity faces dataset\n",
        "from math import sqrt\n",
        "from numpy import load\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# number of growth phase, e.g. 3 = 16x16 images\n",
        "n_blocks = 7\n",
        "# size of the latent space\n",
        "latent_dim = 128\n",
        "# define models\n",
        "d_models = define_discriminator(n_blocks)\n",
        "# define models\n",
        "g_models = define_generator(latent_dim, n_blocks)\n",
        "# define composite models\n",
        "gan_models = define_composite(d_models, g_models)\n",
        "\n",
        "# load image data\n",
        "dataset = all_faces[:1000]\n",
        "# train model\n",
        "train(g_models, d_models, gan_models, dataset, latent_dim, 100, 100, 16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Data (100, 4, 4, 3)\n",
            ">1, d1=0.925, d2=71.708 g=-8.497\n",
            ">2, d1=26.578, d2=265.633 g=12.650\n",
            ">3, d1=34.500, d2=33.194 g=3.576\n",
            ">4, d1=88.534, d2=23.134 g=3.506\n",
            ">5, d1=33.825, d2=44.645 g=-0.607\n",
            ">6, d1=11.510, d2=49.551 g=18.679\n",
            ">7, d1=7.927, d2=19.623 g=-0.280\n",
            ">8, d1=12.884, d2=10.372 g=-6.296\n",
            ">9, d1=5.262, d2=18.786 g=14.706\n",
            ">10, d1=8.889, d2=21.255 g=-10.451\n",
            ">11, d1=5.504, d2=6.713 g=0.012\n",
            ">12, d1=2.197, d2=9.468 g=-12.233\n",
            ">13, d1=3.969, d2=11.459 g=4.887\n",
            ">14, d1=2.352, d2=12.671 g=-12.466\n",
            ">15, d1=2.460, d2=9.536 g=4.048\n",
            ">16, d1=1.492, d2=4.035 g=-6.628\n",
            ">17, d1=1.148, d2=2.536 g=0.948\n",
            ">18, d1=0.262, d2=1.949 g=-4.479\n",
            ">19, d1=0.114, d2=1.663 g=0.057\n",
            ">20, d1=0.099, d2=1.068 g=-2.990\n",
            ">21, d1=0.430, d2=0.939 g=-0.198\n",
            ">22, d1=0.498, d2=1.362 g=-3.653\n",
            ">23, d1=0.218, d2=1.896 g=1.310\n",
            ">24, d1=0.174, d2=3.089 g=-5.243\n",
            ">25, d1=0.440, d2=5.303 g=3.624\n",
            ">26, d1=1.860, d2=5.205 g=-6.136\n",
            ">27, d1=1.194, d2=4.408 g=2.622\n",
            ">28, d1=0.276, d2=4.891 g=-5.640\n",
            ">29, d1=0.383, d2=6.190 g=3.105\n",
            ">30, d1=0.483, d2=6.171 g=-5.618\n",
            ">31, d1=1.572, d2=4.138 g=2.255\n",
            ">32, d1=0.283, d2=3.038 g=-4.109\n",
            ">33, d1=0.218, d2=3.653 g=1.873\n",
            ">34, d1=0.590, d2=3.827 g=-5.054\n",
            ">35, d1=0.555, d2=4.258 g=2.026\n",
            ">36, d1=0.449, d2=3.878 g=-5.100\n",
            ">37, d1=0.989, d2=3.254 g=1.932\n",
            ">38, d1=0.433, d2=2.973 g=-4.651\n",
            ">39, d1=0.354, d2=3.026 g=1.323\n",
            ">40, d1=0.490, d2=2.937 g=-3.716\n",
            ">41, d1=0.359, d2=2.885 g=1.160\n",
            ">42, d1=0.157, d2=2.423 g=-4.363\n",
            ">43, d1=0.099, d2=2.095 g=0.764\n",
            ">44, d1=0.171, d2=1.843 g=-4.239\n",
            ">45, d1=0.091, d2=1.851 g=0.237\n",
            ">46, d1=0.093, d2=2.080 g=-3.681\n",
            ">47, d1=0.124, d2=2.409 g=0.791\n",
            ">48, d1=0.058, d2=2.696 g=-4.548\n",
            ">49, d1=0.048, d2=2.501 g=0.710\n",
            ">50, d1=0.025, d2=2.356 g=-4.257\n",
            ">51, d1=0.127, d2=2.355 g=0.762\n",
            ">52, d1=0.116, d2=2.105 g=-4.299\n",
            ">53, d1=0.085, d2=2.300 g=0.893\n",
            ">54, d1=0.079, d2=2.590 g=-4.529\n",
            ">55, d1=0.129, d2=3.152 g=1.421\n",
            ">56, d1=0.014, d2=3.722 g=-5.051\n",
            ">57, d1=0.088, d2=3.324 g=1.490\n",
            ">58, d1=0.132, d2=3.327 g=-4.571\n",
            ">59, d1=0.119, d2=3.834 g=1.832\n",
            ">60, d1=0.168, d2=3.828 g=-4.301\n",
            ">61, d1=0.075, d2=4.281 g=2.057\n",
            ">62, d1=0.097, d2=4.661 g=-4.943\n",
            ">63, d1=0.044, d2=4.765 g=2.175\n",
            ">64, d1=0.048, d2=5.148 g=-4.794\n",
            ">65, d1=0.053, d2=5.281 g=2.320\n",
            ">66, d1=0.128, d2=4.505 g=-4.498\n",
            ">67, d1=0.379, d2=3.302 g=0.676\n",
            ">68, d1=1.165, d2=2.031 g=-2.294\n",
            ">69, d1=0.257, d2=1.608 g=0.871\n",
            ">70, d1=0.180, d2=1.234 g=-2.334\n",
            ">71, d1=0.209, d2=0.841 g=0.257\n",
            ">72, d1=0.246, d2=0.689 g=-2.245\n",
            ">73, d1=0.160, d2=0.600 g=-0.072\n",
            ">74, d1=0.302, d2=0.451 g=-1.877\n",
            ">75, d1=0.176, d2=0.586 g=0.031\n",
            ">76, d1=0.296, d2=0.615 g=-1.479\n",
            ">77, d1=0.806, d2=0.567 g=0.234\n",
            ">78, d1=1.073, d2=0.451 g=-1.389\n",
            ">79, d1=0.343, d2=0.543 g=0.746\n",
            ">80, d1=0.138, d2=0.643 g=-2.032\n",
            ">81, d1=0.112, d2=0.742 g=0.433\n",
            ">82, d1=0.153, d2=1.016 g=-2.713\n",
            ">83, d1=0.214, d2=1.672 g=1.100\n",
            ">84, d1=0.191, d2=2.587 g=-3.904\n",
            ">85, d1=0.128, d2=3.415 g=1.781\n",
            ">86, d1=0.291, d2=3.795 g=-4.181\n",
            ">87, d1=0.279, d2=4.965 g=2.515\n",
            ">88, d1=0.061, d2=6.810 g=-5.078\n",
            ">89, d1=0.345, d2=7.894 g=2.994\n",
            ">90, d1=0.416, d2=8.613 g=-5.485\n",
            ">91, d1=0.139, d2=8.426 g=2.962\n",
            ">92, d1=0.150, d2=7.829 g=-5.209\n",
            ">93, d1=0.072, d2=6.458 g=1.837\n",
            ">94, d1=0.183, d2=4.277 g=-3.476\n",
            ">95, d1=0.280, d2=2.654 g=0.969\n",
            ">96, d1=0.201, d2=2.013 g=-2.846\n",
            ">97, d1=0.178, d2=1.651 g=0.461\n",
            ">98, d1=0.150, d2=1.496 g=-2.580\n",
            ">99, d1=0.049, d2=1.136 g=0.047\n",
            ">100, d1=0.136, d2=0.753 g=-2.307\n",
            ">101, d1=0.118, d2=0.454 g=-0.452\n",
            ">102, d1=0.030, d2=0.361 g=-1.949\n",
            ">103, d1=0.023, d2=0.325 g=-0.466\n",
            ">104, d1=0.049, d2=0.280 g=-1.677\n",
            ">105, d1=0.109, d2=0.325 g=-0.481\n",
            ">106, d1=0.140, d2=0.536 g=-2.428\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-77d2ee2352f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_faces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-d46f3767d4a0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scaled Data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# train normal or straight-through models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# process each level of growth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-49be00cb8964>\u001b[0m in \u001b[0;36mtrain_epochs\u001b[0;34m(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;31m# update discriminator model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0md_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0md_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0;31m# update the generator via the discriminator's error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mz_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1896\u001b[0m       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n\u001b[1;32m   1897\u001b[0m                                                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m                                                     class_weight)\n\u001b[0m\u001b[1;32m   1899\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[0;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m   \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    699\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \"\"\"\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, name)\u001b[0m\n\u001b[1;32m   4647\u001b[0m         \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4648\u001b[0m         **kwargs)\n\u001b[0;32m-> 4649\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4651\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, variant_tensor)\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_options\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mutable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/options.py\u001b[0m in \u001b[0;36m_set_mutable\u001b[0;34m(self, mutable)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_mutable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautotune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mutable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_distribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mutable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mutable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/options.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    509\u001b[0m       \u001b[0;31m#                 \"Use options.deterministic instead.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"deterministic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}